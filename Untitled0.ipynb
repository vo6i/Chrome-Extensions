{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbsja8ypEpOddY5M38UuP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4afd0ef5cc2646328d80f8d47e31ac30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Вы:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0c7cb104f975466da59e9c8f258fe430",
            "placeholder": "Введите ваш запрос здесь...",
            "style": "IPY_MODEL_bd887ef15e8c45c987c77917d1efc292",
            "value": ""
          }
        },
        "0c7cb104f975466da59e9c8f258fe430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd887ef15e8c45c987c77917d1efc292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d99a15a61b94605bbae78b0b1cde772": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8e4667132f8b40188bcb2e419f75785e",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Вы: Кто здесь? \n",
                  "Модель: боде до бы бы бы себы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы бы \n",
                  "\n"
                ]
              }
            ]
          }
        },
        "8e4667132f8b40188bcb2e419f75785e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vo6i/Chrome-Extensions/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kNsZ132Y6n7",
        "outputId": "9d139eef-e66b-42e6-876e-6a90a2b092c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаю обучение...\n",
            "Эпоха 0, Ошибка: 2.0098\n",
            "Эпоха 50, Ошибка: 0.0078\n",
            "Эпоха 100, Ошибка: 0.0037\n",
            "Эпоха 150, Ошибка: 0.0022\n",
            "\n",
            "Модель говорит: привет как дела нормально пока\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- 1. АРХИТЕКТУРА ---\n",
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, 100, embed_size))\n",
        "        layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(layer, num_layers=2)\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) + self.pos_emb[:, :x.size(1), :]\n",
        "        return self.fc_out(self.transformer(x))\n",
        "\n",
        "# --- 2. ПОДГОТОВКА (ДАННЫЕ) ---\n",
        "# Упрощенный словарь: 0: \"привет\", 1: \"как\", 2: \"дела\", 3: \"нормально\", 4: \"пока\"\n",
        "vocab = {\"привет\": 0, \"как\": 1, \"дела\": 2, \"нормально\": 3, \"пока\": 4}\n",
        "data = torch.tensor([[0, 1, 2, 3, 4]]) # Обучающая фраза\n",
        "\n",
        "model = MiniGPT(vocab_size=5, embed_size=16, num_heads=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- 3. ЦИКЛ ОБУЧЕНИЯ ---\n",
        "print(\"Начинаю обучение...\")\n",
        "for epoch in range(200):\n",
        "    logits = model(data[:, :-1]) # Предсказываем всё кроме первого слова\n",
        "    target = data[:, 1:]         # Цель — следующие слова\n",
        "\n",
        "    loss = criterion(logits.reshape(-1, 5), target.reshape(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Эпоха {epoch}, Ошибка: {loss.item():.4f}\")\n",
        "\n",
        "# --- 4. ПРОВЕРКА (ГЕНЕРАЦИЯ) ---\n",
        "model.eval()\n",
        "input_seq = torch.tensor([[0]]) # Начинаем со слова \"привет\" (0)\n",
        "for _ in range(4):\n",
        "    with torch.no_grad():\n",
        "        out = model(input_seq)\n",
        "        next_id = torch.argmax(out[:, -1, :], dim=-1).unsqueeze(0)\n",
        "        input_seq = torch.cat([input_seq, next_id], dim=1)\n",
        "\n",
        "# Переводим цифры обратно в слова\n",
        "inv_vocab = {v: k for k, v in vocab.items()}\n",
        "result = [inv_vocab[i] for i in input_seq[0].tolist()]\n",
        "print(\"\\nМодель говорит:\", \" \".join(result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# --- 1. АРХИТЕКТУРА МОДЕЛИ ---\n",
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads, block_size):\n",
        "        super(MiniGPT, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        # Упрощенное позиционное кодирование:\n",
        "        self.pos_embedding = nn.Embedding(block_size, embed_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T = x.shape # Batch, Time (sequence length)\n",
        "        # Создаем позиции от 0 до T-1\n",
        "        pos = torch.arange(T, device=x.device).unsqueeze(0) # [1, T]\n",
        "\n",
        "        tok_emb = self.embedding(x) # [B, T, E]\n",
        "        pos_emb = self.pos_embedding(pos) # [1, T, E]\n",
        "\n",
        "        out = tok_emb + pos_emb # Складываем смысл и позицию\n",
        "        out = self.transformer(out)\n",
        "        logits = self.fc_out(out)\n",
        "        return logits\n",
        "\n",
        "# --- 2. ПОДГОТОВКА ДАННЫХ (СИМВОЛЬНЫЙ ТОКЕНИЗАТОР) ---\n",
        "# Замени этот текст на свой (загрузи файл в Colab и прочитай его)\n",
        "# Или используй пример из скриншота\n",
        "text = \"привет как дела нормально пока\" * 100 # Увеличим текст для обучения\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# --- 3. НАСТРОЙКИ ОБУЧЕНИЯ ---\n",
        "BLOCK_SIZE = 8   # Сколько символов смотрим за раз\n",
        "BATCH_SIZE = 4   # Сколько примеров обрабатываем параллельно\n",
        "EMBED_SIZE = 32\n",
        "HEADS = 2\n",
        "LR = 0.001\n",
        "\n",
        "model = MiniGPT(vocab_size, EMBED_SIZE, HEADS, BLOCK_SIZE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- 4. ЦИКЛ ОБУЧЕНИЯ ---\n",
        "print(f\"Начинаю обучение на {len(data)} символах, размер словаря: {vocab_size}\")\n",
        "model.train()\n",
        "\n",
        "for epoch in range(100):\n",
        "    # Генерация случайного батча данных из текста\n",
        "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "    xb = torch.stack([data[i:i+BLOCK_SIZE] for i in ix]) # input (контекст)\n",
        "    yb = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix]) # target (что должно быть дальше)\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(xb)\n",
        "    B, T, C = logits.shape\n",
        "    loss = criterion(logits.view(B*T, C), yb.view(B*T)) # Расчет ошибки\n",
        "\n",
        "    # Backward pass и оптимизация\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Эпоха {epoch}, Ошибка: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Обучение завершено.\")\n",
        "\n",
        "# --- 5. ГЕНЕРАЦИЯ ТЕКСТА ---\n",
        "model.eval()\n",
        "context = torch.zeros((1, 1), dtype=torch.long) # Начинаем с пустоты (0-й токен)\n",
        "\n",
        "print(\"\\nГенерация (должно быть похоже на 'привет...'):\")\n",
        "for _ in range(50):\n",
        "    # Обрезаем контекст до максимального размера блока, чтобы не перегружать модель\n",
        "    context_cond = context[:, -BLOCK_SIZE:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(context_cond)\n",
        "        # Берем только последний временной шаг (последний символ)\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # Выбираем следующий символ случайным образом (семплируем)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        # Добавляем выбранный токен к контексту\n",
        "        context = torch.cat((context, next_token), dim=1)\n",
        "\n",
        "print(decode(context[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtwogdCDaN2F",
        "outputId": "ff37e023-88e5-4f69-b5c3-4787852ae928"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаю обучение на 3000 символах, размер словаря: 15\n",
            "Эпоха 0, Ошибка: 2.7463\n",
            "Эпоха 10, Ошибка: 1.7450\n",
            "Эпоха 20, Ошибка: 1.4876\n",
            "Эпоха 30, Ошибка: 1.4169\n",
            "Эпоха 40, Ошибка: 1.1304\n",
            "Эпоха 50, Ошибка: 0.9566\n",
            "Эпоха 60, Ошибка: 0.9045\n",
            "Эпоха 70, Ошибка: 0.8405\n",
            "Эпоха 80, Ошибка: 0.8724\n",
            "Эпоха 90, Ошибка: 0.7185\n",
            "Обучение завершено.\n",
            "\n",
            "Генерация (должно быть похоже на 'привет...'):\n",
            " какак дет дельа деа но привмаьно примат ривепдет к\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import sys # Импортируем для работы с пользовательским вводом\n",
        "\n",
        "# --- 1. АРХИТЕКТУРА МОДЕЛИ (из наших прошлых обсуждений) ---\n",
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads, block_size):\n",
        "        super(MiniGPT, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.pos_embedding = nn.Embedding(block_size, embed_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T = x.shape\n",
        "        pos = torch.arange(T, device=x.device).unsqueeze(0)\n",
        "        tok_emb = self.embedding(x)\n",
        "        pos_emb = self.pos_embedding(pos)\n",
        "        out = tok_emb + pos_emb\n",
        "        out = self.transformer(out)\n",
        "        logits = self.fc_out(out)\n",
        "        return logits\n",
        "\n",
        "# --- 2. ПОДГОТОВКА ДАННЫХ (используем код с твоего скриншота) ---\n",
        "# ИМЯ ВАШЕГО ФАЙЛА В COLAB\n",
        "FILE_NAME = 'book.txt'\n",
        "\n",
        "try:\n",
        "    with open(FILE_NAME, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    print(f\"Успешно прочитан файл: {FILE_NAME}, размер текста: {len(text)} символов.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Ошибка: файл '{FILE_NAME}' не найден. Использую fallback текст.\")\n",
        "    text = \"привет как дела нормально пока\" # Fallback текст для теста\n",
        "\n",
        "# Создаем словарь на основе всех символов в вашем файле\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f\"Данные закодированы в тензор размером: {data.shape}\")\n",
        "\n",
        "# --- 3. НАСТРОЙКИ ОБУЧЕНИЯ ---\n",
        "BLOCK_SIZE = 16 # Увеличим размер контекста для лучшего диалога # Adjusted from 64 to 16\n",
        "BATCH_SIZE = 16\n",
        "EMBED_SIZE = 64\n",
        "HEADS = 4\n",
        "LR = 0.001\n",
        "EPOCHS = 1000 # Увеличим эпохи для лучшего результата\n",
        "\n",
        "model = MiniGPT(vocab_size, EMBED_SIZE, HEADS, BLOCK_SIZE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- 4. ЦИКЛ ОБУЧЕНИЯ ---\n",
        "print(\"Начинаю обучение...\")\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "    xb = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
        "    yb = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
        "\n",
        "    logits = model(xb)\n",
        "    B, T, C = logits.shape\n",
        "    loss = criterion(logits.view(B*T, C), yb.view(B*T))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Эпоха {epoch}, Ошибка: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Обучение завершено.\")\n",
        "\n",
        "\n",
        "# --- 5. ГЕНЕРАЦИЯ ТЕКСТА И ПОЛЬЗОВАТЕЛЬСКИЙ ВВОД (по мотивам твоего скриншота) ---\n",
        "model.eval()\n",
        "\n",
        "def generate_response(prompt_text, max_len=100):\n",
        "    context = torch.tensor(encode(prompt_text), dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        context_cond = context[:, -BLOCK_SIZE:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(context_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # Используем argmax для более детерминированных ответов\n",
        "            next_token = torch.argmax(probs, dim=-1).unsqueeze(0)\n",
        "\n",
        "            context = torch.cat((context, next_token), dim=1)\n",
        "\n",
        "    full_output = decode(context.tolist()[0])\n",
        "    response_start_index = len(prompt_text)\n",
        "    return full_output[response_start_index:]\n",
        "\n",
        "# --- Цикл общения с пользователем ---\n",
        "print(\"\\n--- Режим Диалога ---\")\n",
        "print(\"Введите текст для генерации или 'выход' для завершения.\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"Вы: \")\n",
        "        if user_input.lower() == 'выход':\n",
        "            print(\"Завершение диалога.\")\n",
        "            break\n",
        "\n",
        "        response = generate_response(user_input)\n",
        "        print(f\"Модель: {response}\\n\")\n",
        "    except EOFError:\n",
        "        # Обработка завершения ввода в Colab\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Произошла ошибка ввода: {e}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5XL2y2Mc-2f",
        "outputId": "109c3e19-77da-43f5-ad78-fe14fe2a584a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Успешно прочитан файл: book.txt, размер текста: 2796 символов.\n",
            "Данные закодированы в тензор размером: torch.Size([2796])\n",
            "Начинаю обучение...\n",
            "Эпоха 0, Ошибка: 4.0798\n",
            "Эпоха 100, Ошибка: 1.2086\n",
            "Эпоха 200, Ошибка: 0.2080\n",
            "Эпоха 300, Ошибка: 0.2063\n",
            "Эпоха 400, Ошибка: 0.1183\n",
            "Эпоха 500, Ошибка: 0.1697\n",
            "Эпоха 600, Ошибка: 0.1452\n",
            "Эпоха 700, Ошибка: 0.1312\n",
            "Эпоха 800, Ошибка: 0.1289\n",
            "Эпоха 900, Ошибка: 0.1161\n",
            "Обучение завершено.\n",
            "\n",
            "--- Режим Диалога ---\n",
            "Введите текст для генерации или 'выход' для завершения.\n",
            "Вы: Привет\n",
            "Модель: тииимоееее е етете еелете е еелете еелете еелете еелете еелете еелете еелете еелете еелете еелете ее\n",
            "\n",
            "Вы: Как ты? \n",
            "Модель:  какаах твоя любимая свем сверемесе себем сереть свем свере врете реретре реререрреррерррррррррррррр\n",
            "\n",
            "Вы: Ты сошел с ума? \n",
            "Произошла ошибка ввода: 'Т'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- УСТАНОВКА БИБЛИОТЕК ---\n",
        "!pip install ipywidgets\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# --- 1. АРХИТЕКТУРА МОДЕЛИ ---\n",
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads, block_size):\n",
        "        super(MiniGPT, self).__init__()\n",
        "        self.block_size = block_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.pos_embedding = nn.Embedding(block_size, embed_size)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T = x.shape\n",
        "        pos = torch.arange(T, device=x.device).unsqueeze(0)\n",
        "        tok_emb = self.embedding(x)\n",
        "        pos_emb = self.pos_embedding(pos)\n",
        "        out = tok_emb + pos_emb\n",
        "        out = self.transformer(out)\n",
        "        logits = self.fc_out(out)\n",
        "        return logits\n",
        "\n",
        "# --- 2. ПОДГОТОВКА ДАННЫХ ---\n",
        "FILE_NAME = 'book.txt'\n",
        "\n",
        "try:\n",
        "    with open(FILE_NAME, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    print(f\"Успешно прочитан файл: {FILE_NAME}, размер текста: {len(text)} символов.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Ошибка: файл '{FILE_NAME}' не найден. Использую fallback текст.\")\n",
        "    text = \"привет как дела нормально пока\" * 100\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f\"Данные закодированы в тензор размером: {data.shape}\")\n",
        "\n",
        "# --- 3. НАСТРОЙКИ ОБУЧЕНИЯ И ИНИЦИАЛИЗАЦИЯ ---\n",
        "BLOCK_SIZE = 64\n",
        "BATCH_SIZE = 16\n",
        "EMBED_SIZE = 64\n",
        "HEADS = 4\n",
        "LR = 0.001\n",
        "EPOCHS = 200 # Уменьшим для скорости теста в Colab\n",
        "\n",
        "model = MiniGPT(vocab_size, EMBED_SIZE, HEADS, BLOCK_SIZE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- 4. ЦИКЛ ОБУЧЕНИЯ ---\n",
        "print(\"Начинаю обучение...\")\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "    xb = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
        "    yb = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
        "\n",
        "    logits = model(xb)\n",
        "    B, T, C = logits.shape\n",
        "    loss = criterion(logits.view(B*T, C), yb.view(B*T))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Эпоха {epoch}, Ошибка: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Обучение завершено.\")\n",
        "\n",
        "# --- 5. СОХРАНЕНИЕ МОДЕЛИ ---\n",
        "MODEL_PATH = 'minigpt_checkpoint.pt'\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(f\"Модель сохранена в файл {MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9b0WzRogF8s",
        "outputId": "fbbf0c83-d2ec-4949-be5e-0e15f7804a66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.24.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.5.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.30.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.11)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.3)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Успешно прочитан файл: book.txt, размер текста: 2796 символов.\n",
            "Данные закодированы в тензор размером: torch.Size([2796])\n",
            "Начинаю обучение...\n",
            "Эпоха 0, Ошибка: 4.1045\n",
            "Эпоха 50, Ошибка: 2.4059\n",
            "Эпоха 100, Ошибка: 2.1605\n",
            "Эпоха 150, Ошибка: 2.0873\n",
            "Обучение завершено.\n",
            "Модель сохранена в файл minigpt_checkpoint.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. ЗАГРУЗКА СОХРАНЕННОЙ МОДЕЛИ (модель должна быть уже определена в ячейке 1) ---\n",
        "# Создаем новый экземпляр модели с теми же параметрами\n",
        "loaded_model = MiniGPT(vocab_size, EMBED_SIZE, HEADS, BLOCK_SIZE)\n",
        "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "loaded_model.eval() # Переводим в режим оценки/инференса\n",
        "\n",
        "print(f\"Модель загружена из файла {MODEL_PATH}\")\n",
        "\n",
        "# --- 2. ФУНКЦИЯ ГЕНЕРАЦИИ (использует loaded_model) ---\n",
        "def generate_response(prompt_text, max_len=100):\n",
        "    context = torch.tensor(encode(prompt_text), dtype=torch.long).unsqueeze(0)\n",
        "    for _ in range(max_len):\n",
        "        context_cond = context[:, -BLOCK_SIZE:]\n",
        "        with torch.no_grad():\n",
        "            logits = loaded_model(context_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_token = torch.argmax(probs, dim=-1).unsqueeze(0)\n",
        "            context = torch.cat((context, next_token), dim=1)\n",
        "\n",
        "    full_output = decode(context.tolist()[0])\n",
        "    response_start_index = len(prompt_text)\n",
        "    return full_output[response_start_index:]\n",
        "\n",
        "# --- 3. ЦИКЛ ОБЩЕНИЯ С ПОЛЬЗОВАТЕЛЕМ (ipywidgets) ---\n",
        "print(\"\\n--- Режим Диалога (с ipywidgets) ---\")\n",
        "text_input = widgets.Text(placeholder='Введите ваш запрос здесь...', description='Вы:')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(sender):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        user_input = sender.value\n",
        "        if user_input.lower() == 'выход':\n",
        "            print(\"Завершение диалога.\")\n",
        "            text_input.disabled = True\n",
        "            return\n",
        "        response = generate_response(user_input)\n",
        "        print(f\"Вы: {user_input}\")\n",
        "        print(f\"Модель: {response}\\n\")\n",
        "        sender.value = ''\n",
        "\n",
        "text_input.on_submit(on_submit)\n",
        "display(text_input, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "4afd0ef5cc2646328d80f8d47e31ac30",
            "0c7cb104f975466da59e9c8f258fe430",
            "bd887ef15e8c45c987c77917d1efc292",
            "1d99a15a61b94605bbae78b0b1cde772",
            "8e4667132f8b40188bcb2e419f75785e"
          ]
        },
        "id": "g8laK1KHgf-G",
        "outputId": "89505610-7e7b-4aa4-915f-059994d5104d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель загружена из файла minigpt_checkpoint.pt\n",
            "\n",
            "--- Режим Диалога (с ipywidgets) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Вы:', placeholder='Введите ваш запрос здесь...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4afd0ef5cc2646328d80f8d47e31ac30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d99a15a61b94605bbae78b0b1cde772"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}